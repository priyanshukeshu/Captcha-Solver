{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses inputs from https://www.kaggle.com/fanbyprinciple/preprocessing-and-segmenting-letters-from-captcha/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSOo7kT1RFyx90c6H9P3WnHYeRKOqHp-NlOdA&usqp=CAU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /opt/anaconda3/lib/python3.11/site-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in /opt/anaconda3/lib/python3.11/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /opt/anaconda3/lib/python3.11/site-packages (from kaggle) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil in /opt/anaconda3/lib/python3.11/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from kaggle) (4.66.4)\n",
      "Requirement already satisfied: python-slugify in /opt/anaconda3/lib/python3.11/site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in /opt/anaconda3/lib/python3.11/site-packages (from kaggle) (2.0.7)\n",
      "Requirement already satisfied: bleach in /opt/anaconda3/lib/python3.11/site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from bleach->kaggle) (23.1)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.11/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/anaconda3/lib/python3.11/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests->kaggle) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/priyanshukumar/.kaggle/kaggle.json'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# Step 1: Set up kaggle.json\n",
    "os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
    "shutil.copy('kaggle.json', os.path.expanduser('~/.kaggle/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/priyanshukumar/.kaggle/kaggle.json'\n",
      "Source code downloaded to /Users/priyanshukumar/Downloads/creating-a-captcha-solver.ipynb\n"
     ]
    }
   ],
   "source": [
    "!kaggle kernels pull fantao/creating-a-captcha-solver -p /path/to/directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T06:32:43.436441Z",
     "iopub.status.busy": "2024-10-31T06:32:43.435924Z",
     "iopub.status.idle": "2024-10-31T06:32:43.448340Z",
     "shell.execute_reply": "2024-10-31T06:32:43.446971Z",
     "shell.execute_reply.started": "2024-10-31T06:32:43.436328Z"
    }
   },
   "outputs": [],
   "source": [
    "captcha_processing_output_folder = \"../input/preprocessing-and-segmenting-letters-from-captcha/extracted_letter_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T06:44:08.079572Z",
     "iopub.status.busy": "2024-10-31T06:44:08.079150Z",
     "iopub.status.idle": "2024-10-31T06:44:08.125609Z",
     "shell.execute_reply": "2024-10-31T06:44:08.124460Z",
     "shell.execute_reply.started": "2024-10-31T06:44:08.079537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (0,)\n",
      "Labels shape: (0,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def resize_image_to_dimensions(image, desired_width, desired_height):\n",
    "    \"\"\"Resizes an image to the desired dimensions, maintaining aspect ratio and padding if necessary.\"\"\"\n",
    "    # Ensure image has three dimensions (height, width, channels)\n",
    "    if image.shape[-1] != 1:\n",
    "        image = tf.expand_dims(image, axis=-1)\n",
    "    \n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # Resize the image while keeping the aspect ratio\n",
    "    if w > h:\n",
    "        scale_ratio = desired_width / w\n",
    "        new_size = (desired_width, int(h * scale_ratio))\n",
    "    else:\n",
    "        scale_ratio = desired_height / h\n",
    "        new_size = (int(w * scale_ratio), desired_height)\n",
    "    \n",
    "    resized_image = tf.image.resize(image, new_size)\n",
    "\n",
    "    # Add padding to achieve the exact desired dimensions\n",
    "    image_with_border = tf.image.resize_with_crop_or_pad(\n",
    "        resized_image, desired_height, desired_width\n",
    "    )\n",
    "\n",
    "    return image_with_border\n",
    "\n",
    "def read_image(image_file_path):\n",
    "    \"\"\"Reads an image file, converts it to grayscale, resizes it, and adds a channel dimension.\"\"\"\n",
    "    # Load the image in grayscale using TensorFlow\n",
    "    img = tf.io.read_file(image_file_path)\n",
    "    img = tf.image.decode_image(img, channels=1)  # Grayscale image (1 channel)\n",
    "    \n",
    "    # Resize to 20x20 pixels\n",
    "    img = resize_image_to_dimensions(img, 20, 20)\n",
    "    \n",
    "    # Normalize to [0,1] range\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Set the folder containing the CAPTCHA images\n",
    "captcha_processing_output_folder = \"../input/preprocessing-and-segmenting-letters-from-captcha/extracted_letter_images\"\n",
    "\n",
    "# Initialize lists to hold images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through each image in the specified directory\n",
    "for image_file_name in os.listdir(captcha_processing_output_folder):\n",
    "    # Construct full image path\n",
    "    full_image_path = os.path.join(captcha_processing_output_folder, image_file_name)\n",
    "    \n",
    "    # Check if it's a file (skip directories)\n",
    "    if os.path.isfile(full_image_path):\n",
    "        # Read and process the image\n",
    "        image_file = read_image(full_image_path)\n",
    "        \n",
    "        # Extract the label (assuming the label is the character in the filename, before the extension)\n",
    "        label = os.path.splitext(image_file_name)[0]  # Gets file name without extension\n",
    "        \n",
    "        # Append the image and label to their respective lists\n",
    "        images.append(image_file)\n",
    "        labels.append(label)\n",
    "\n",
    "# Convert lists to NumPy arrays and normalize images\n",
    "images = np.array(images, dtype=\"float32\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Optionally, you can check the shape of images and labels\n",
    "print(f'Images shape: {images.shape}')\n",
    "print(f'Labels shape: {labels.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T06:44:10.293788Z",
     "iopub.status.busy": "2024-10-31T06:44:10.293396Z",
     "iopub.status.idle": "2024-10-31T06:44:11.452149Z",
     "shell.execute_reply": "2024-10-31T06:44:11.450943Z",
     "shell.execute_reply.started": "2024-10-31T06:44:10.293755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  4  6  8  A  C  E  G\tJ  L  N  Q  S  U  W  Y\n",
      "3  5  7  9  B  D  F  H\tK  M  P  R  T  V  X  Z\n"
     ]
    }
   ],
   "source": [
    "!dir ../input/preprocessing-and-segmenting-letters-from-captcha/extracted_letter_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T06:44:12.280544Z",
     "iopub.status.busy": "2024-10-31T06:44:12.280121Z",
     "iopub.status.idle": "2024-10-31T06:46:34.165293Z",
     "shell.execute_reply": "2024-10-31T06:46:34.164297Z",
     "shell.execute_reply.started": "2024-10-31T06:44:12.280504Z"
    }
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Get all image paths\n",
    "img_paths = tf.io.gfile.glob(os.path.join(captcha_processing_output_folder, '*', '*.png'))\n",
    "\n",
    "# Iterate through each image path\n",
    "for image_file_path in img_paths:\n",
    "    # Read and process the image\n",
    "    image_file = read_image(image_file_path)\n",
    "    \n",
    "    # Extract the label (assuming the label is the folder name containing the image)\n",
    "    label = os.path.basename(os.path.dirname(image_file_path))\n",
    "    \n",
    "    # Append the image and label to their respective lists\n",
    "    images.append(image_file)\n",
    "    labels.append(label)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T06:46:34.167416Z",
     "iopub.status.busy": "2024-10-31T06:46:34.167094Z",
     "iopub.status.idle": "2024-10-31T06:46:34.235778Z",
     "shell.execute_reply": "2024-10-31T06:46:34.234742Z",
     "shell.execute_reply.started": "2024-10-31T06:46:34.167384Z"
    }
   },
   "outputs": [],
   "source": [
    "images = np.array(images, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T06:53:02.863490Z",
     "iopub.status.busy": "2024-10-31T06:53:02.862958Z",
     "iopub.status.idle": "2024-10-31T06:53:02.869602Z",
     "shell.execute_reply": "2024-10-31T06:53:02.868564Z",
     "shell.execute_reply.started": "2024-10-31T06:53:02.863448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38744"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T06:56:26.680934Z",
     "iopub.status.busy": "2024-10-31T06:56:26.680543Z",
     "iopub.status.idle": "2024-10-31T06:56:26.731897Z",
     "shell.execute_reply": "2024-10-31T06:56:26.730834Z",
     "shell.execute_reply.started": "2024-10-31T06:56:26.680900Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T06:56:27.009877Z",
     "iopub.status.busy": "2024-10-31T06:56:27.009489Z",
     "iopub.status.idle": "2024-10-31T06:56:27.016345Z",
     "shell.execute_reply": "2024-10-31T06:56:27.015317Z",
     "shell.execute_reply.started": "2024-10-31T06:56:27.009843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30995, 20, 20, 1), (7749, 20, 20, 1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T06:56:29.196654Z",
     "iopub.status.busy": "2024-10-31T06:56:29.196257Z",
     "iopub.status.idle": "2024-10-31T06:56:29.201380Z",
     "shell.execute_reply": "2024-10-31T06:56:29.200160Z",
     "shell.execute_reply.started": "2024-10-31T06:56:29.196621Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T06:56:29.593287Z",
     "iopub.status.busy": "2024-10-31T06:56:29.592850Z",
     "iopub.status.idle": "2024-10-31T06:56:29.607739Z",
     "shell.execute_reply": "2024-10-31T06:56:29.606596Z",
     "shell.execute_reply.started": "2024-10-31T06:56:29.593248Z"
    }
   },
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer().fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T06:56:31.509979Z",
     "iopub.status.busy": "2024-10-31T06:56:31.509595Z",
     "iopub.status.idle": "2024-10-31T06:56:31.516335Z",
     "shell.execute_reply": "2024-10-31T06:56:31.515195Z",
     "shell.execute_reply.started": "2024-10-31T06:56:31.509946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C', '9', 'W', ..., 'S', '3', 'V'], dtype='<U1')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T06:56:32.078722Z",
     "iopub.status.busy": "2024-10-31T06:56:32.078326Z",
     "iopub.status.idle": "2024-10-31T06:56:32.104056Z",
     "shell.execute_reply": "2024-10-31T06:56:32.103126Z",
     "shell.execute_reply.started": "2024-10-31T06:56:32.078673Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = label_binarizer.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T06:56:34.996761Z",
     "iopub.status.busy": "2024-10-31T06:56:34.996190Z",
     "iopub.status.idle": "2024-10-31T06:56:35.005178Z",
     "shell.execute_reply": "2024-10-31T06:56:35.003897Z",
     "shell.execute_reply.started": "2024-10-31T06:56:34.996702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T06:56:42.764765Z",
     "iopub.status.busy": "2024-10-31T06:56:42.764376Z",
     "iopub.status.idle": "2024-10-31T06:56:42.770735Z",
     "shell.execute_reply": "2024-10-31T06:56:42.769744Z",
     "shell.execute_reply.started": "2024-10-31T06:56:42.764733Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30995, 32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T06:56:45.276223Z",
     "iopub.status.busy": "2024-10-31T06:56:45.275746Z",
     "iopub.status.idle": "2024-10-31T06:56:45.287674Z",
     "shell.execute_reply": "2024-10-31T06:56:45.286581Z",
     "shell.execute_reply.started": "2024-10-31T06:56:45.276182Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test = label_binarizer.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T06:56:52.479458Z",
     "iopub.status.busy": "2024-10-31T06:56:52.479083Z",
     "iopub.status.idle": "2024-10-31T06:56:52.485249Z",
     "shell.execute_reply": "2024-10-31T06:56:52.484097Z",
     "shell.execute_reply.started": "2024-10-31T06:56:52.479424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7749, 32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T07:00:25.972180Z",
     "iopub.status.busy": "2024-10-31T07:00:25.971746Z",
     "iopub.status.idle": "2024-10-31T07:00:26.171258Z",
     "shell.execute_reply": "2024-10-31T07:00:26.170152Z",
     "shell.execute_reply.started": "2024-10-31T07:00:25.972145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 20, 20, 20)        520       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 20, 20, 20)        80        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 20, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 40)        20040     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 20, 20, 40)        160       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 20, 40)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 40)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 80)        80080     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 10, 80)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 10, 10, 160)       320160    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 10, 160)       640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 160)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               2048512   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                16416     \n",
      "=================================================================\n",
      "Total params: 2,488,976\n",
      "Trainable params: 2,487,352\n",
      "Non-trainable params: 1,624\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "num_classes = 32\n",
    "NN_model = Sequential()\n",
    "\n",
    "# First convolutional block\n",
    "NN_model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=(20, 20, 1), activation=\"relu\"))\n",
    "NN_model.add(BatchNormalization())\n",
    "NN_model.add(Dropout(0.25))  # Add dropout\n",
    "\n",
    "# Second convolutional block\n",
    "NN_model.add(Conv2D(40, (5, 5), padding=\"same\", activation=\"relu\"))\n",
    "NN_model.add(BatchNormalization())\n",
    "NN_model.add(Dropout(0.25))  # Add dropout\n",
    "NN_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Third convolutional block\n",
    "NN_model.add(Conv2D(80, (5, 5), padding=\"same\", activation=\"relu\"))\n",
    "NN_model.add(BatchNormalization())\n",
    "\n",
    "# Fourth convolutional block\n",
    "NN_model.add(Conv2D(160, (5, 5), padding=\"same\", activation=\"relu\"))\n",
    "NN_model.add(BatchNormalization())\n",
    "NN_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Flatten and fully connected layers\n",
    "NN_model.add(Flatten())\n",
    "NN_model.add(Dense(512, activation=\"relu\"))\n",
    "NN_model.add(BatchNormalization())\n",
    "NN_model.add(Dropout(0.5))  # Higher dropout for dense layer\n",
    "\n",
    "# Output layer\n",
    "NN_model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "NN_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Display the model summary\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=16,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPTCHA = \"../input/captcha-images/captcha_images/256Q.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(CAPTCHA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bounding_rectangles_of_contours(contours):\n",
    "    \"\"\"Determines the bounding rectangles of the contours of the cropped letters.\"\"\"\n",
    "    letter_bounding_rectangles = []\n",
    "    for contour in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        if w / h > 1.25:\n",
    "            half_width = int(w / 2)\n",
    "            letter_bounding_rectangles.append((x, y, half_width, h))\n",
    "            letter_bounding_rectangles.append((x + half_width, y, half_width, h))\n",
    "        else:\n",
    "            letter_bounding_rectangles.append((x, y, w, h))\n",
    "    return letter_bounding_rectangles\n",
    "\n",
    "\n",
    "def preprocess_CAPTCHA(img):\n",
    "    \"\"\"Takes a CAPTCHA image and thresholds it.\"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_with_border = cv2.copyMakeBorder(gray, 8, 8, 8, 8, cv2.BORDER_REPLICATE)\n",
    "    preprocessed = cv2.threshold(\n",
    "        gray_with_border, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU\n",
    "    )[1]\n",
    "    return gray_with_border, preprocessed\n",
    "\n",
    "\n",
    "def get_CAPTCHA_label(path_to_file):\n",
    "    \"\"\"Get the CAPTCHA text from the file name.\"\"\"\n",
    "    filename = os.path.basename(path_to_file)\n",
    "    label = filename.split(\".\")[0]\n",
    "    return label\n",
    "\n",
    "\n",
    "def CAPTCHA_to_gray_scale_and_bounding_rectangles(captcha_image_file):\n",
    "    \"\"\"Take a CAPTCHA and output a grayscale version as well as the bounding rectangles of its cropped letters.\"\"\"\n",
    "    image = cv2.imread(captcha_image_file)\n",
    "    gray, preprocessed = preprocess_CAPTCHA(image)\n",
    "    contours = cv2.findContours(\n",
    "        preprocessed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    contours = contours[0]\n",
    "    letter_bounding_rectangles = find_bounding_rectangles_of_contours(contours)\n",
    "    letter_bounding_rectangles = sorted(letter_bounding_rectangles, key=lambda x: x[0])\n",
    "    return gray, letter_bounding_rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captcha_label = get_CAPTCHA_label(CAPTCHA)\n",
    "gray, letter_bounding_rectangles = CAPTCHA_to_gray_scale_and_bounding_rectangles(\n",
    "    CAPTCHA\n",
    ")\n",
    "predictions = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter_bounding_rectangle in letter_bounding_rectangles:\n",
    "    x, y, w, h = letter_bounding_rectangle\n",
    "    letter_image = gray[y - 2 : y + h + 2, x - 2 : x + w + 2]\n",
    "    letter_image = resize_image_to_dimensions(letter_image, 20, 20)\n",
    "    letter_image = np.expand_dims(letter_image, axis=2)\n",
    "    letter_image = np.expand_dims(letter_image, axis=0)\n",
    "    prediction = NN_model.predict(letter_image)\n",
    "    letter = label_binarizer.inverse_transform(prediction)[0]\n",
    "    predictions.append(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_captcha_text = \"\".join(predictions)\n",
    "print(f\"predicted CAPTCHA text is: {predicted_captcha_text}\")\n",
    "print(f\"captch text is : 256Q\")\n",
    "\n",
    "\n",
    "# it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(read_image(CAPTCHA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1347855,
     "sourceId": 2242900,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 63207135,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30096,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
